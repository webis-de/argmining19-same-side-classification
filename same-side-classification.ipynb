{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Clasiification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id')\n",
    "cross_test_df =  pd.read_csv(data_cross_path.format('test'),index_col='id')\n",
    "\n",
    "within_traindev_df =  pd.read_csv(data_within_path.format('training'), index_col='id')\n",
    "within_test_df =  pd.read_csv(data_within_path.format('test'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1 :\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1 :\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#74517\n",
    "within_traindev_df.loc[82134]['argument2']\n",
    "#within_traindev_df.loc[74517]['argument2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df[(within_traindev_df['tag'] == 'gay marriage') & (within_traindev_df['tag'] == 'gay marriage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within_traindev_df[(within_traindev_df['tag'] == 'gay marriage') and (within_traindev_df['is_same_side'] == 'True')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_overview(df, task = 'same-side', class_name = 'is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task, '\\n\\n')\n",
    "    print('Total instances: ', total)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        \n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t',is_same_side, ': ', len(side_df), ' instances')\n",
    "            \n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))))\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    arguments_length_lst = [len(word_tokenize(x)) for x in df['argument1'].values]\n",
    "    arguments_length_lst.extend([len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('shortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('longest argument:', max(arguments_length_lst), ' words')\n",
    "    print('aargument average length:', np.mean(arguments_length_lst), ' words')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    arguments_sent_length_lst = [len(sent_tokenize(x)) for x in df['argument1'].values]\n",
    "    arguments_sent_length_lst.extend([len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('shortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('longest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('aargument average length:', np.mean(arguments_sent_length_lst), ' sentences')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "def get_train_test_sets(df):\n",
    "    X = df[['argument1', 'argument2', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "        \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "def lemmatize_stemming(token, pos_tag):\n",
    "    stemmer = SnowballStemmer(\"english\") #pOrter, M. \"An algorithm for suffix stripping.\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(token, pos=pos_tag))\n",
    "\n",
    "def preprocess(text):\n",
    "    lemma = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('\\n', ' ').strip()\n",
    "        tokens = [token for token in word_tokenize(sentence)]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        for idx in range(0,len(tokens)):\n",
    "            token = tokens[idx].lower()\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "                wordnet_pos = get_wordnet_pos(pos_tags[idx][1])\n",
    "                l_ = lemmatize_stemming(token, wordnet_pos)\n",
    "                lemma.append(l_)\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(row):\n",
    "    row['argument1_lemmas'] = preprocess(row['argument1'])\n",
    "    row['argument2_lemmas'] = preprocess(row['argument2'])\n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting n grams lemma for argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "def extract_ngrams(X_train, X_dev, col, idx='id'):\n",
    "    vectorizer = CountVectorizer(min_df=600, max_df=0.7, ngram_range=(3, 3), max_features=5000 )\n",
    "    \n",
    "    vectorizer.fit(X_train[col])\n",
    "    features = vectorizer.transform(X_train[col])\n",
    "    features_dev = vectorizer.transform(X_dev[col])\n",
    "\n",
    "    train_df =pd.DataFrame(\n",
    "        features.todense(),\n",
    "        columns=vectorizer.get_feature_names()\n",
    "    )\n",
    "    train_df = train_df.add_prefix(col)\n",
    "\n",
    "    \n",
    "    aid_df = X_train[[idx]]\n",
    "\n",
    "    train_df = train_df.merge(aid_df, left_index =True, right_index=True, suffixes=(False, False), how='inner')\n",
    "    train_df.set_index(idx, inplace=True)    \n",
    "    \n",
    "    dev_df =pd.DataFrame(\n",
    "        features_dev.todense(),\n",
    "        columns=vectorizer.get_feature_names()\n",
    "    )\n",
    "    dev_df = dev_df.add_prefix(col)\n",
    "\n",
    "    \n",
    "    aid_dev_df = X_dev[[idx]]\n",
    "\n",
    "    dev_df = dev_df.merge(aid_dev_df, left_index =True, right_index=True, suffixes=(False, False), how='inner')\n",
    "    dev_df.set_index(idx, inplace=True)\n",
    "    return train_df, dev_df\n",
    "\n",
    "def extract_n_grams_features(X_train, X_dev, columns, idx='id'): \n",
    "\n",
    "    X_train = X_train.reset_index()\n",
    "    result_train_df =  X_train[[idx]]\n",
    "    result_train_df.set_index(idx, inplace=True)\n",
    "    \n",
    "    \n",
    "    X_dev = X_dev.reset_index()\n",
    "    result_dev_df =  X_dev[[idx]]\n",
    "    result_dev_df.set_index(idx, inplace=True)\n",
    "    \n",
    "    for col in columns:\n",
    "        result_train_df_, result_dev_df_ = extract_ngrams(X_train, X_dev, col)\n",
    "        result_train_df = result_train_df.join(result_train_df_)\n",
    "        result_dev_df = result_dev_df.join(result_dev_df_)\n",
    "    return result_train_df, result_dev_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_test_svm(X_train, y_train, X_test):\n",
    "    scaler = StandardScaler(copy=True, with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    \n",
    "    svclassifier = SVC(kernel='linear')  \n",
    "    svclassifier.fit(X_train, y_train)  \n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svclassifier.predict(X_test) \n",
    "\n",
    "    return y_pred\n",
    "def report_training_results(y_test, y_pred):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    f1_dic = {}\n",
    "    \n",
    "    f1_dic['macro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "X_train = X_train.apply(get_lemma, axis=1)\n",
    "X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "X_train_, X_dev_ = extract_n_grams_features(X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4 train \n",
    "y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5 Evaluate\n",
    "report_training_results(y_dev, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
